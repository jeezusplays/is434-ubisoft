{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora, models\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "target_column = 'rawContent'\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"your_data.csv\")\n",
    "texts = df[target_column].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ubisoft', 107584), ('I', 57887), ('game', 44403), ('creed', 17293), ('assassin', 17045), ('get', 14713), ('thank', 13330), ('play', 11542), ('de', 11434), ('please', 10896), ('new', 10677), ('like', 10388), ('make', 9886), ('one', 8661), ('go', 8184), ('good', 7769), ('issue', 7493), ('far', 6816), ('look', 6751), ('xbox', 6722)]\n"
     ]
    }
   ],
   "source": [
    "# Initialize spaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Cleaning function\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "cleaned_texts = [clean_text(text) for text in texts]\n",
    "\n",
    "# Tokenization and Lemmatization\n",
    "def tokenize_lemmatize(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc if token.is_alpha and token.lemma_ not in stop_words]\n",
    "\n",
    "tokenized_texts = [tokenize_lemmatize(text) for text in cleaned_texts]\n",
    "\n",
    "# Assuming 'tokenized_texts' is your list of tokenized tweets\n",
    "all_words = [word for text in tokenized_texts for word in text]\n",
    "word_freq = Counter(all_words)\n",
    "print(word_freq.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Topics: 10\n",
      "Coherence Score: 0.35409867276042295\n",
      "Perplexity: -7.631308156811642\n",
      "Topic: 0\n",
      "Words: 0.050*\"game\" + 0.042*\"make\" + 0.023*\"hey\" + 0.020*\"try\" + 0.017*\"team\" + 0.014*\"time\" + 0.014*\"well\" + 0.013*\"think\" + 0.013*\"support\" + 0.013*\"back\"\n",
      "\n",
      "Topic: 1\n",
      "Words: 0.040*\"siege\" + 0.039*\"pc\" + 0.033*\"rainbow\" + 0.029*\"six\" + 0.028*\"free\" + 0.026*\"hope\" + 0.023*\"win\" + 0.021*\"division\" + 0.021*\"console\" + 0.019*\"since\"\n",
      "\n",
      "Topic: 2\n",
      "Words: 0.139*\"creed\" + 0.138*\"assassin\" + 0.031*\"give\" + 0.026*\"guy\" + 0.018*\"long\" + 0.017*\"unity\" + 0.016*\"series\" + 0.013*\"driver\" + 0.012*\"anything\" + 0.012*\"reveal\"\n",
      "\n",
      "Topic: 3\n",
      "Words: 0.154*\"thank\" + 0.051*\"de\" + 0.037*\"fix\" + 0.028*\"open\" + 0.020*\"gameplay\" + 0.018*\"la\" + 0.018*\"en\" + 0.018*\"que\" + 0.015*\"red\" + 0.015*\"th\"\n",
      "\n",
      "Topic: 4\n",
      "Words: 0.035*\"please\" + 0.025*\"issue\" + 0.024*\"gt\" + 0.017*\"still\" + 0.017*\"work\" + 0.017*\"sorry\" + 0.014*\"get\" + 0.014*\"know\" + 0.014*\"take\" + 0.014*\"let\"\n",
      "\n",
      "Topic: 5\n",
      "Words: 0.057*\"update\" + 0.049*\"use\" + 0.043*\"beta\" + 0.036*\"check\" + 0.036*\"cell\" + 0.035*\"splinter\" + 0.032*\"black\" + 0.025*\"edition\" + 0.024*\"experience\" + 0.020*\"tom\"\n",
      "\n",
      "Topic: 6\n",
      "Words: 0.191*\"I\" + 0.048*\"game\" + 0.035*\"get\" + 0.028*\"like\" + 0.020*\"would\" + 0.020*\"good\" + 0.019*\"play\" + 0.019*\"go\" + 0.017*\"want\" + 0.016*\"watch\"\n",
      "\n",
      "Topic: 7\n",
      "Words: 0.054*\"game\" + 0.049*\"new\" + 0.045*\"release\" + 0.032*\"video\" + 0.032*\"come\" + 0.023*\"help\" + 0.022*\"xbox\" + 0.020*\"ubi\" + 0.019*\"nintendo\" + 0.019*\"ps\"\n",
      "\n",
      "Topic: 8\n",
      "Words: 0.067*\"one\" + 0.050*\"far\" + 0.038*\"cry\" + 0.028*\"dm\" + 0.024*\"look\" + 0.022*\"great\" + 0.021*\"bad\" + 0.019*\"send\" + 0.017*\"love\" + 0.015*\"title\"\n",
      "\n",
      "Topic: 9\n",
      "Words: 0.030*\"alive\" + 0.029*\"de\" + 0.028*\"dance\" + 0.025*\"e\" + 0.022*\"u\" + 0.020*\"lol\" + 0.019*\"information\" + 0.019*\"rayman\" + 0.018*\"ever\" + 0.014*\"order\"\n",
      "\n",
      "Number of Topics: 20\n",
      "Coherence Score: 0.3786213369255041\n",
      "Perplexity: -7.614391942178966\n",
      "Topic: 0\n",
      "Words: 0.057*\"I\" + 0.051*\"game\" + 0.039*\"make\" + 0.021*\"hey\" + 0.018*\"team\" + 0.018*\"try\" + 0.016*\"think\" + 0.015*\"time\" + 0.014*\"people\" + 0.013*\"well\"\n",
      "\n",
      "Topic: 1\n",
      "Words: 0.042*\"siege\" + 0.042*\"pc\" + 0.034*\"rainbow\" + 0.030*\"next\" + 0.030*\"six\" + 0.029*\"free\" + 0.028*\"hope\" + 0.022*\"console\" + 0.020*\"fun\" + 0.019*\"happy\"\n",
      "\n",
      "Topic: 2\n",
      "Words: 0.134*\"creed\" + 0.134*\"assassin\" + 0.030*\"give\" + 0.025*\"guy\" + 0.019*\"rt\" + 0.017*\"long\" + 0.016*\"series\" + 0.016*\"unity\" + 0.013*\"driver\" + 0.012*\"anything\"\n",
      "\n",
      "Topic: 3\n",
      "Words: 0.159*\"thank\" + 0.053*\"de\" + 0.038*\"fix\" + 0.030*\"open\" + 0.020*\"gameplay\" + 0.018*\"que\" + 0.018*\"en\" + 0.018*\"la\" + 0.015*\"red\" + 0.015*\"th\"\n",
      "\n",
      "Topic: 4\n",
      "Words: 0.033*\"please\" + 0.024*\"issue\" + 0.022*\"gt\" + 0.020*\"know\" + 0.016*\"still\" + 0.016*\"work\" + 0.016*\"sorry\" + 0.015*\"get\" + 0.013*\"let\" + 0.013*\"hi\"\n",
      "\n",
      "Topic: 5\n",
      "Words: 0.054*\"update\" + 0.048*\"use\" + 0.041*\"beta\" + 0.038*\"experience\" + 0.035*\"check\" + 0.034*\"cell\" + 0.033*\"splinter\" + 0.032*\"black\" + 0.026*\"division\" + 0.025*\"edition\"\n",
      "\n",
      "Topic: 6\n",
      "Words: 0.160*\"I\" + 0.042*\"game\" + 0.038*\"get\" + 0.031*\"like\" + 0.023*\"would\" + 0.019*\"want\" + 0.018*\"watch\" + 0.018*\"play\" + 0.015*\"good\" + 0.015*\"go\"\n",
      "\n",
      "Topic: 7\n",
      "Words: 0.049*\"new\" + 0.048*\"release\" + 0.046*\"game\" + 0.035*\"come\" + 0.032*\"video\" + 0.025*\"help\" + 0.023*\"xbox\" + 0.022*\"ubi\" + 0.021*\"nintendo\" + 0.019*\"playstation\"\n",
      "\n",
      "Topic: 8\n",
      "Words: 0.068*\"game\" + 0.062*\"one\" + 0.046*\"far\" + 0.035*\"cry\" + 0.028*\"love\" + 0.027*\"good\" + 0.021*\"great\" + 0.020*\"bad\" + 0.017*\"new\" + 0.016*\"show\"\n",
      "\n",
      "Topic: 9\n",
      "Words: 0.034*\"rayman\" + 0.030*\"u\" + 0.029*\"alive\" + 0.028*\"de\" + 0.027*\"dance\" + 0.020*\"lol\" + 0.019*\"information\" + 0.018*\"ever\" + 0.015*\"ticket\" + 0.014*\"order\"\n",
      "\n",
      "Number of Topics: 30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFull\u001b[0m                                      Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\is434\\Lib\\site-packages\\gensim\\models\\ldamulticore.py:298\u001b[0m, in \u001b[0;36mLdaMulticore.update\u001b[1;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     \u001b[43mjob_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     queue_size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\is434\\Lib\\multiprocessing\\queues.py:90\u001b[0m, in \u001b[0;36mQueue.put\u001b[1;34m(self, obj, block, timeout)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sem\u001b[38;5;241m.\u001b[39macquire(block, timeout):\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Full\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_notempty:\n",
      "\u001b[1;31mFull\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m passes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m\n\u001b[0;32m     21\u001b[0m random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m\n\u001b[1;32m---> 23\u001b[0m lda_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLdaMulticore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid2word\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_topics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_word_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     32\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Compute Coherence Score\u001b[39;00m\n\u001b[0;32m     37\u001b[0m coherence_model_lda \u001b[38;5;241m=\u001b[39m CoherenceModel(model\u001b[38;5;241m=\u001b[39mlda_model, texts\u001b[38;5;241m=\u001b[39mtokenized_texts, dictionary\u001b[38;5;241m=\u001b[39mdictionary, coherence\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_v\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\is434\\Lib\\site-packages\\gensim\\models\\ldamulticore.py:186\u001b[0m, in \u001b[0;36mLdaMulticore.__init__\u001b[1;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(alpha, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m alpha \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto-tuning alpha not implemented in LdaMulticore; use plain LdaModel.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 186\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mLdaMulticore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_topics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid2word\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid2word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminimum_probability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminimum_probability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminimum_phi_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminimum_phi_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_word_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mper_word_topics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\is434\\Lib\\site-packages\\gensim\\models\\ldamodel.py:521\u001b[0m, in \u001b[0;36mLdaModel.__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    519\u001b[0m use_numpy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    520\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 521\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks_as_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_numpy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    524\u001b[0m     msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    525\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\is434\\Lib\\site-packages\\gensim\\models\\ldamulticore.py:309\u001b[0m, in \u001b[0;36mLdaMulticore.update\u001b[1;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mFull:\n\u001b[0;32m    307\u001b[0m             \u001b[38;5;66;03m# in case the input job queue is full, keep clearing the\u001b[39;00m\n\u001b[0;32m    308\u001b[0m             \u001b[38;5;66;03m# result queue, to make sure we don't deadlock\u001b[39;00m\n\u001b[1;32m--> 309\u001b[0m             \u001b[43mprocess_result_queue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m     process_result_queue()\n\u001b[0;32m    312\u001b[0m \u001b[38;5;66;03m# endfor single corpus pass\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \n\u001b[0;32m    314\u001b[0m \u001b[38;5;66;03m# wait for all outstanding jobs to finish\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\is434\\Lib\\site-packages\\gensim\\models\\ldamulticore.py:274\u001b[0m, in \u001b[0;36mLdaMulticore.update.<locals>.process_result_queue\u001b[1;34m(force)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03mClear the result queue, merging all intermediate results, and update the\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03mLDA model if necessary.\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    273\u001b[0m merged_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mresult_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    275\u001b[0m     other\u001b[38;5;241m.\u001b[39mmerge(result_queue\u001b[38;5;241m.\u001b[39mget())\n\u001b[0;32m    276\u001b[0m     queue_size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\is434\\Lib\\multiprocessing\\queues.py:129\u001b[0m, in \u001b[0;36mQueue.empty\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mempty\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\is434\\Lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\is434\\Lib\\multiprocessing\\connection.py:346\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    344\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\is434\\Lib\\multiprocessing\\connection.py:900\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n\u001b[1;32m--> 900\u001b[0m         ov\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;66;03m# wait for all overlapped reads to stop\u001b[39;00m\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "custom_stopwords = {'ubisoft', 'game', 'go', 'get', 'I'}\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(custom_stopwords)\n",
    "\n",
    "\n",
    "\n",
    "# Create Dictionary and Corpus\n",
    "dictionary = corpora.Dictionary(tokenized_texts)\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
    "\n",
    "# Build LDA Model\n",
    "max_topics = 100\n",
    "step = 10\n",
    "for num_topics in range(10, max_topics+step, step):\n",
    "    print(f\"Number of Topics: {num_topics}\")\n",
    "    num_topics = 10\n",
    "    passes = 15\n",
    "    random_state = 42\n",
    "\n",
    "    lda_model = models.LdaMulticore(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary,\n",
    "        num_topics=num_topics,\n",
    "        random_state=random_state,\n",
    "        chunksize=100,\n",
    "        passes=passes,\n",
    "        workers=4,\n",
    "        per_word_topics=True\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=tokenized_texts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model_lda.get_coherence()\n",
    "    print(f'Coherence Score: {coherence_score}')\n",
    "    \n",
    "    perplexity = lda_model.log_perplexity(corpus)\n",
    "    print(f'Perplexity: {perplexity}')\n",
    "\n",
    "    # Print Topics\n",
    "    for idx, topic in lda_model.print_topics(-1):\n",
    "        print(f\"Topic: {idx}\\nWords: {topic}\\n\")\n",
    "\n",
    "    # Visualize Topics\n",
    "    lda_vis = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "    # Uncomment the line below to display the visualization in the notebook\n",
    "    # pyLDAvis.display(data=lda_vis)\n",
    "    pyLDAvis.save_html(lda_vis, f'lda_visualization_topic_{num_topics}.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\is434\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\is434\\Lib\\site-packages\\umap\\__init__.py:36: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\is434\\Lib\\site-packages\\pkg_resources\\__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>62770</td>\n",
       "      <td>-1_they_but_it_like</td>\n",
       "      <td>[they, but, it, like, them, their, and, dont, ...</td>\n",
       "      <td>[Just finished Assassin's Creed, and all I can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3214</td>\n",
       "      <td>0_rainbow6uk_titaniumrolo_ubisoftuk_lol</td>\n",
       "      <td>[rainbow6uk, titaniumrolo, ubisoftuk, lol, pre...</td>\n",
       "      <td>[@TitaniumRolo @Rainbow6_UK @Rainbow6Game @Ubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1370</td>\n",
       "      <td>1_assassinsfr_assassinscreed_assassinsuk_ubiso...</td>\n",
       "      <td>[assassinsfr, assassinscreed, assassinsuk, ubi...</td>\n",
       "      <td>[@CreedKells @Ubisoft @UbisoftDE @UbisoftFR @U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>910</td>\n",
       "      <td>2_servers_server_down_fix</td>\n",
       "      <td>[servers, server, down, fix, ubisoftsupport, u...</td>\n",
       "      <td>[@Ubisoft servers down?, @Ubisoft are the serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>905</td>\n",
       "      <td>3_ac_ac3_ac4_ac2</td>\n",
       "      <td>[ac, ac3, ac4, ac2, ac1, acu, origins, acs, ac...</td>\n",
       "      <td>[@Ubisoft @assassinscreed Best AC game, @Ubiso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>2260</td>\n",
       "      <td>10</td>\n",
       "      <td>2260_varsitygamingtv_crackheaded_httpstcofwbpz...</td>\n",
       "      <td>[varsitygamingtv, crackheaded, httpstcofwbpz2j...</td>\n",
       "      <td>[@VarsityGamingTV Come on. You knew this would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>2261</td>\n",
       "      <td>10</td>\n",
       "      <td>2261_fc5_mzammadkhan_chiranramgobin_thatsgroov...</td>\n",
       "      <td>[fc5, mzammadkhan, chiranramgobin, thatsgroovy...</td>\n",
       "      <td>[@RustyPennyy What platform do you play FC5 on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>2262</td>\n",
       "      <td>10</td>\n",
       "      <td>2262_promises_modern_return_httptcow6slz9vzw0</td>\n",
       "      <td>[promises, modern, return, httptcow6slz9vzw0, ...</td>\n",
       "      <td>[Ubisoft Promises Modern Day Story Will Return...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>2263</td>\n",
       "      <td>10</td>\n",
       "      <td>2263_httptinyurlcombu64oy_httptcoey34fpn5_http...</td>\n",
       "      <td>[httptinyurlcombu64oy, httptcoey34fpn5, httpbi...</td>\n",
       "      <td>[@FalseShepard we're working on getting more @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>2264</td>\n",
       "      <td>10</td>\n",
       "      <td>2264_itsa_ame_mario_uncle</td>\n",
       "      <td>[itsa, ame, mario, uncle, memariobad, marioo, ...</td>\n",
       "      <td>[Best part of AC2 is meeting Uncle Mario. \"ITS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2266 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic  Count                                               Name  \\\n",
       "0        -1  62770                                -1_they_but_it_like   \n",
       "1         0   3214            0_rainbow6uk_titaniumrolo_ubisoftuk_lol   \n",
       "2         1   1370  1_assassinsfr_assassinscreed_assassinsuk_ubiso...   \n",
       "3         2    910                          2_servers_server_down_fix   \n",
       "4         3    905                                   3_ac_ac3_ac4_ac2   \n",
       "...     ...    ...                                                ...   \n",
       "2261   2260     10  2260_varsitygamingtv_crackheaded_httpstcofwbpz...   \n",
       "2262   2261     10  2261_fc5_mzammadkhan_chiranramgobin_thatsgroov...   \n",
       "2263   2262     10      2262_promises_modern_return_httptcow6slz9vzw0   \n",
       "2264   2263     10  2263_httptinyurlcombu64oy_httptcoey34fpn5_http...   \n",
       "2265   2264     10                          2264_itsa_ame_mario_uncle   \n",
       "\n",
       "                                         Representation  \\\n",
       "0     [they, but, it, like, them, their, and, dont, ...   \n",
       "1     [rainbow6uk, titaniumrolo, ubisoftuk, lol, pre...   \n",
       "2     [assassinsfr, assassinscreed, assassinsuk, ubi...   \n",
       "3     [servers, server, down, fix, ubisoftsupport, u...   \n",
       "4     [ac, ac3, ac4, ac2, ac1, acu, origins, acs, ac...   \n",
       "...                                                 ...   \n",
       "2261  [varsitygamingtv, crackheaded, httpstcofwbpz2j...   \n",
       "2262  [fc5, mzammadkhan, chiranramgobin, thatsgroovy...   \n",
       "2263  [promises, modern, return, httptcow6slz9vzw0, ...   \n",
       "2264  [httptinyurlcombu64oy, httptcoey34fpn5, httpbi...   \n",
       "2265  [itsa, ame, mario, uncle, memariobad, marioo, ...   \n",
       "\n",
       "                                    Representative_Docs  \n",
       "0     [Just finished Assassin's Creed, and all I can...  \n",
       "1     [@TitaniumRolo @Rainbow6_UK @Rainbow6Game @Ubi...  \n",
       "2     [@CreedKells @Ubisoft @UbisoftDE @UbisoftFR @U...  \n",
       "3     [@Ubisoft servers down?, @Ubisoft are the serv...  \n",
       "4     [@Ubisoft @assassinscreed Best AC game, @Ubiso...  \n",
       "...                                                 ...  \n",
       "2261  [@VarsityGamingTV Come on. You knew this would...  \n",
       "2262  [@RustyPennyy What platform do you play FC5 on...  \n",
       "2263  [Ubisoft Promises Modern Day Story Will Return...  \n",
       "2264  [@FalseShepard we're working on getting more @...  \n",
       "2265  [Best part of AC2 is meeting Uncle Mario. \"ITS...  \n",
       "\n",
       "[2266 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import OpenAI\n",
    "\n",
    "OPEN_AI_API_KEY = \"your_openai_api_key\"\n",
    "client = openai.OpenAI(api_key=OPEN_AI_API_KEY)\n",
    "representation_model = OpenAI(client, model=\"gpt-4o-mini\", chat=True)\n",
    "topic_model = BERTopic(representation_model=representation_model,language=\"multilingual\")\n",
    "\n",
    "topics, probabilities = topic_model.fit_transform(texts)\n",
    "\n",
    "# Explore topics\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
