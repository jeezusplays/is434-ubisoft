{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora, models\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "target_column = 'rawContent'\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"your_data.csv\")\n",
    "texts = df[target_column].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize spaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Cleaning function\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "cleaned_texts = [clean_text(text) for text in texts]\n",
    "\n",
    "# Tokenization and Lemmatization\n",
    "def tokenize_lemmatize(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc if token.is_alpha and token.lemma_ not in stop_words]\n",
    "\n",
    "tokenized_texts = [tokenize_lemmatize(text) for text in cleaned_texts]\n",
    "\n",
    "# Assuming 'tokenized_texts' is your list of tokenized tweets\n",
    "all_words = [word for text in tokenized_texts for word in text]\n",
    "word_freq = Counter(all_words)\n",
    "print(word_freq.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Topics: 10\n",
      "Number of Topics: 20\n",
      "Number of Topics: 30\n",
      "Number of Topics: 40\n",
      "Number of Topics: 50\n",
      "Number of Topics: 60\n",
      "Number of Topics: 70\n",
      "Number of Topics: 80\n",
      "Number of Topics: 90\n",
      "Number of Topics: 100\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "custom_stopwords = {'ubisoft', 'game', 'go', 'get', 'I'}\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(custom_stopwords)\n",
    "\n",
    "\n",
    "\n",
    "# Create Dictionary and Corpus\n",
    "dictionary = corpora.Dictionary(tokenized_texts)\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
    "\n",
    "# Build LDA Model\n",
    "max_topics = 100\n",
    "step = 10\n",
    "for num_topics in range(10, max_topics+step, step):\n",
    "    print(f\"Number of Topics: {num_topics}\")\n",
    "    num_topics = 10\n",
    "    passes = 15\n",
    "    random_state = 42\n",
    "\n",
    "    lda_model = models.LdaMulticore(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary,\n",
    "        num_topics=num_topics,\n",
    "        random_state=random_state,\n",
    "        update_every=1,\n",
    "        chunksize=100,\n",
    "        passes=passes,\n",
    "        alpha='auto',\n",
    "        workers=4,\n",
    "        per_word_topics=True\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=tokenized_texts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model_lda.get_coherence()\n",
    "    print(f'Coherence Score: {coherence_score}')\n",
    "    \n",
    "    perplexity = lda_model.log_perplexity(corpus)\n",
    "    print(f'Perplexity: {perplexity}')\n",
    "\n",
    "    # Print Topics\n",
    "    for idx, topic in lda_model.print_topics(-1):\n",
    "        print(f\"Topic: {idx}\\nWords: {topic}\\n\")\n",
    "\n",
    "    # Visualize Topics\n",
    "    lda_vis = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "    # Uncomment the line below to display the visualization in the notebook\n",
    "    # pyLDAvis.display(data=lda_vis)\n",
    "    pyLDAvis.save_html(lda_vis, f'lda_visualization_topic_{num_topics}.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\is434\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\is434\\Lib\\site-packages\\umap\\__init__.py:36: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\is434\\Lib\\site-packages\\pkg_resources\\__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>62770</td>\n",
       "      <td>-1_they_but_it_like</td>\n",
       "      <td>[they, but, it, like, them, their, and, dont, ...</td>\n",
       "      <td>[Just finished Assassin's Creed, and all I can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3214</td>\n",
       "      <td>0_rainbow6uk_titaniumrolo_ubisoftuk_lol</td>\n",
       "      <td>[rainbow6uk, titaniumrolo, ubisoftuk, lol, pre...</td>\n",
       "      <td>[@TitaniumRolo @Rainbow6_UK @Rainbow6Game @Ubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1370</td>\n",
       "      <td>1_assassinsfr_assassinscreed_assassinsuk_ubiso...</td>\n",
       "      <td>[assassinsfr, assassinscreed, assassinsuk, ubi...</td>\n",
       "      <td>[@CreedKells @Ubisoft @UbisoftDE @UbisoftFR @U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>910</td>\n",
       "      <td>2_servers_server_down_fix</td>\n",
       "      <td>[servers, server, down, fix, ubisoftsupport, u...</td>\n",
       "      <td>[@Ubisoft servers down?, @Ubisoft are the serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>905</td>\n",
       "      <td>3_ac_ac3_ac4_ac2</td>\n",
       "      <td>[ac, ac3, ac4, ac2, ac1, acu, origins, acs, ac...</td>\n",
       "      <td>[@Ubisoft @assassinscreed Best AC game, @Ubiso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>2260</td>\n",
       "      <td>10</td>\n",
       "      <td>2260_varsitygamingtv_crackheaded_httpstcofwbpz...</td>\n",
       "      <td>[varsitygamingtv, crackheaded, httpstcofwbpz2j...</td>\n",
       "      <td>[@VarsityGamingTV Come on. You knew this would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>2261</td>\n",
       "      <td>10</td>\n",
       "      <td>2261_fc5_mzammadkhan_chiranramgobin_thatsgroov...</td>\n",
       "      <td>[fc5, mzammadkhan, chiranramgobin, thatsgroovy...</td>\n",
       "      <td>[@RustyPennyy What platform do you play FC5 on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>2262</td>\n",
       "      <td>10</td>\n",
       "      <td>2262_promises_modern_return_httptcow6slz9vzw0</td>\n",
       "      <td>[promises, modern, return, httptcow6slz9vzw0, ...</td>\n",
       "      <td>[Ubisoft Promises Modern Day Story Will Return...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>2263</td>\n",
       "      <td>10</td>\n",
       "      <td>2263_httptinyurlcombu64oy_httptcoey34fpn5_http...</td>\n",
       "      <td>[httptinyurlcombu64oy, httptcoey34fpn5, httpbi...</td>\n",
       "      <td>[@FalseShepard we're working on getting more @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>2264</td>\n",
       "      <td>10</td>\n",
       "      <td>2264_itsa_ame_mario_uncle</td>\n",
       "      <td>[itsa, ame, mario, uncle, memariobad, marioo, ...</td>\n",
       "      <td>[Best part of AC2 is meeting Uncle Mario. \"ITS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2266 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic  Count                                               Name  \\\n",
       "0        -1  62770                                -1_they_but_it_like   \n",
       "1         0   3214            0_rainbow6uk_titaniumrolo_ubisoftuk_lol   \n",
       "2         1   1370  1_assassinsfr_assassinscreed_assassinsuk_ubiso...   \n",
       "3         2    910                          2_servers_server_down_fix   \n",
       "4         3    905                                   3_ac_ac3_ac4_ac2   \n",
       "...     ...    ...                                                ...   \n",
       "2261   2260     10  2260_varsitygamingtv_crackheaded_httpstcofwbpz...   \n",
       "2262   2261     10  2261_fc5_mzammadkhan_chiranramgobin_thatsgroov...   \n",
       "2263   2262     10      2262_promises_modern_return_httptcow6slz9vzw0   \n",
       "2264   2263     10  2263_httptinyurlcombu64oy_httptcoey34fpn5_http...   \n",
       "2265   2264     10                          2264_itsa_ame_mario_uncle   \n",
       "\n",
       "                                         Representation  \\\n",
       "0     [they, but, it, like, them, their, and, dont, ...   \n",
       "1     [rainbow6uk, titaniumrolo, ubisoftuk, lol, pre...   \n",
       "2     [assassinsfr, assassinscreed, assassinsuk, ubi...   \n",
       "3     [servers, server, down, fix, ubisoftsupport, u...   \n",
       "4     [ac, ac3, ac4, ac2, ac1, acu, origins, acs, ac...   \n",
       "...                                                 ...   \n",
       "2261  [varsitygamingtv, crackheaded, httpstcofwbpz2j...   \n",
       "2262  [fc5, mzammadkhan, chiranramgobin, thatsgroovy...   \n",
       "2263  [promises, modern, return, httptcow6slz9vzw0, ...   \n",
       "2264  [httptinyurlcombu64oy, httptcoey34fpn5, httpbi...   \n",
       "2265  [itsa, ame, mario, uncle, memariobad, marioo, ...   \n",
       "\n",
       "                                    Representative_Docs  \n",
       "0     [Just finished Assassin's Creed, and all I can...  \n",
       "1     [@TitaniumRolo @Rainbow6_UK @Rainbow6Game @Ubi...  \n",
       "2     [@CreedKells @Ubisoft @UbisoftDE @UbisoftFR @U...  \n",
       "3     [@Ubisoft servers down?, @Ubisoft are the serv...  \n",
       "4     [@Ubisoft @assassinscreed Best AC game, @Ubiso...  \n",
       "...                                                 ...  \n",
       "2261  [@VarsityGamingTV Come on. You knew this would...  \n",
       "2262  [@RustyPennyy What platform do you play FC5 on...  \n",
       "2263  [Ubisoft Promises Modern Day Story Will Return...  \n",
       "2264  [@FalseShepard we're working on getting more @...  \n",
       "2265  [Best part of AC2 is meeting Uncle Mario. \"ITS...  \n",
       "\n",
       "[2266 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "# Initialize BERTopic\n",
    "topic_model = BERTopic()\n",
    "topics, probabilities = topic_model.fit_transform(texts)\n",
    "\n",
    "# Explore topics\n",
    "topic_model.get_topic_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
